{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_eluvio_codes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MT0BP4HGUE6",
        "outputId": "f7ca59dc-62fc-4da6-c84e-e596428c4c47"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZqZxJeYMWTd",
        "outputId": "1bc92c41-2e8b-4585-c0f1-1849f3fd5e6f"
      },
      "source": [
        "!pip install focal-loss"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting focal-loss\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/96/babb0f40b2046a45aa2263773d915a34f02d4fb6bae91a505ce2db8ab0b2/focal_loss-0.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.7/dist-packages (from focal-loss) (2.4.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.15.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.7.4.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.3.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.2)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (2.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (1.12.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2->focal-loss) (0.36.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (54.2.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.10.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (2.10)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.4.1)\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBx74M5mMj-N"
      },
      "source": [
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Suppress TF info\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from focal_loss import BinaryFocalLoss\n",
        "import time\n",
        "from numpy import save\n",
        "from keras.models import load_model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7w-ClIwou5k"
      },
      "source": [
        "**This portion of the code is to extract the 4 Sub-datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vC4yUze-9Oo"
      },
      "source": [
        "directory = '/content/drive/MyDrive/data'\n",
        "files = os.listdir(directory) \n",
        "total_files = len(files) #Calculate total number of files \n",
        "windows_in_dataset = np.zeros((total_files), dtype = np.uint16) #since maximum number of shots in dataset is 3096"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1hUa1m8-8yH"
      },
      "source": [
        "l = 0\n",
        "window = 7 # Window needs to be an int greater than 1 and odd!\n",
        "first = int((window - 1)/2)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW0P_4my_HCZ",
        "outputId": "d5f81731-10c1-4fe3-e612-80b4f2c2314b"
      },
      "source": [
        "for i in range(18,35):\n",
        "    \n",
        "    filename = directory + '/' + files[i]\n",
        "    f = open(filename, 'rb')\n",
        "    data = pickle.load(f)\n",
        "    f.close()\n",
        "        \n",
        "    feat1 = data['place']\n",
        "    feat1 = feat1.data.numpy() #convert tensors into numpy arrays for sklearn\n",
        "    feat1_size = feat1.shape[1]\n",
        "    \n",
        "    feat2 = data['cast']\n",
        "    feat2 = feat2.data.numpy()\n",
        "    feat2_size = feat2.shape[1]\n",
        "    \n",
        "    feat3 = data['action']\n",
        "    feat3 = feat3.data.numpy()\n",
        "    feat3_size = feat3.shape[1]\n",
        "    \n",
        "    feat4 = data['audio']\n",
        "    feat4 = feat4.data.numpy()\n",
        "    feat4_size = feat4.shape[1]\n",
        "    \n",
        "    x = np.hstack((feat1, feat2, feat3, feat4))\n",
        "    y = data['scene_transition_boundary_ground_truth']\n",
        "            \n",
        "    scaler = preprocessing.MinMaxScaler().fit(x)\n",
        "    x_scaled = scaler.transform(x)\n",
        "\n",
        "    # Pad the start and end with zeros \n",
        "    padding = np.zeros((first, x_scaled.shape[1]))\n",
        "    x_scaled = np.concatenate((padding, x_scaled, padding), axis=0)\n",
        "    N = x_scaled.shape[0] \n",
        "    j = 0\n",
        "    GT = []\n",
        "\n",
        "    for p in range(first, (N - first) - 1):\n",
        "        temp1 = x_scaled[p - first: p + first + 1, :]\n",
        "        temp1 = np.reshape(temp1, (1, window, temp1.shape[1]))\n",
        "        \n",
        "        temp2 = y[p - first].data.numpy()\n",
        "        temp2 = str(temp2)\n",
        "        if(j == 0):\n",
        "            X = temp1\n",
        "        else:\n",
        "            X = np.concatenate((X, temp1), axis=0)\n",
        "\n",
        "        GT.append(temp2)\n",
        "        j = j + 1    \n",
        "\n",
        "    print('Iter ID:',i,' ','Array size for X:', X.shape,' ','Grount Truth Size:',len(GT))\n",
        "\n",
        "    if (l == 0):\n",
        "        X_data = X\n",
        "        Y_data = GT\n",
        "    else:\n",
        "        X_data = np.concatenate((X_data, X), axis = 0)\n",
        "        Y_data.extend(GT)\n",
        "           \n",
        "    l = l + 1\n",
        "\n",
        "print('X_data')\n",
        "print('Final array size:', ' ', X_data.shape, ' ', len(Y_data))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter ID: 18   Array size for X: (1783, 7, 3584)   Grount Truth Size: 1783\n",
            "Iter ID: 19   Array size for X: (1301, 7, 3584)   Grount Truth Size: 1301\n",
            "Iter ID: 20   Array size for X: (3095, 7, 3584)   Grount Truth Size: 3095\n",
            "Iter ID: 21   Array size for X: (1999, 7, 3584)   Grount Truth Size: 1999\n",
            "Iter ID: 22   Array size for X: (1069, 7, 3584)   Grount Truth Size: 1069\n",
            "Iter ID: 23   Array size for X: (1211, 7, 3584)   Grount Truth Size: 1211\n",
            "Iter ID: 24   Array size for X: (1536, 7, 3584)   Grount Truth Size: 1536\n",
            "Iter ID: 25   Array size for X: (1779, 7, 3584)   Grount Truth Size: 1779\n",
            "Iter ID: 26   Array size for X: (2033, 7, 3584)   Grount Truth Size: 2033\n",
            "Iter ID: 27   Array size for X: (759, 7, 3584)   Grount Truth Size: 759\n",
            "Iter ID: 28   Array size for X: (1150, 7, 3584)   Grount Truth Size: 1150\n",
            "Iter ID: 29   Array size for X: (1396, 7, 3584)   Grount Truth Size: 1396\n",
            "Iter ID: 30   Array size for X: (1176, 7, 3584)   Grount Truth Size: 1176\n",
            "Iter ID: 31   Array size for X: (1062, 7, 3584)   Grount Truth Size: 1062\n",
            "Iter ID: 32   Array size for X: (2397, 7, 3584)   Grount Truth Size: 2397\n",
            "Iter ID: 33   Array size for X: (664, 7, 3584)   Grount Truth Size: 664\n",
            "Iter ID: 34   Array size for X: (2608, 7, 3584)   Grount Truth Size: 2608\n",
            "X_data\n",
            "Final array size:   (27018, 7, 3584)   27018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgC7yfBB_J4H",
        "outputId": "d3498650-4fc9-4e54-fa8f-277d7116e15c"
      },
      "source": [
        "M = len(Y_data)\n",
        "#print('Y_gt')\n",
        "Y_gt = np.zeros((M), dtype = np.uint8)\n",
        "for i in range(M):\n",
        "    if(Y_data[i] == 'True'):\n",
        "        Y_gt[i] = 1\n",
        "    elif(Y_data[i] == 'False'):\n",
        "        Y_gt[i] = 0\n",
        "\n",
        "# save array to file for easy load later\n",
        "print('Saving array to file \\n')\n",
        "out_filename = '/content/drive/MyDrive/eluvio/datasets/dataset18-34.npz'\n",
        "print(out_filename)\n",
        "np.savez_compressed(out_filename, a = X_data, b = Y_gt) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving array to file \n",
            "\n",
            "/content/drive/MyDrive/eluvio/datasets/dataset18-34.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR3pUVEppN36"
      },
      "source": [
        "**This cell is to enable the GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn7_AnB_Mm-z",
        "outputId": "fee99145-1063-4ea3-e5b8-92f6b51cbde3"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not Found')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime!')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not Found\n",
            "Your runtime has 13.7 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqvO_tclMpu8"
      },
      "source": [
        "window = 7 # Window needs to be an int greater than 1 and odd!\n",
        "first = int((window - 1)/2)\n",
        "array_dims = np.zeros((4), dtype = np.int32)\n",
        "array_dims[0] = 2048\n",
        "array_dims[1] = 512 #feat1_size + feat2_size\n",
        "array_dims[2] = 512 #feat1_size + feat2_size + feat3_size\n",
        "array_dims[3] = 512 #feat1_size + feat2_size + feat3_size + feat4_size"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9H982VsqejV"
      },
      "source": [
        "**The data is loaded here from the sub-dataset** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek4qtAkAMsoX",
        "outputId": "4da62ae3-b9b9-4a40-97d3-30ee683dead4"
      },
      "source": [
        "filename1 = '/content/drive/MyDrive/eluvio/datasets/dataset0-17.npz'\n",
        "loaded1 = np.load(filename1)\n",
        "X1 = loaded1['a']\n",
        "Y1 = loaded1['b']\n",
        "print(filename1, X1.shape, Y1.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/eluvio/datasets/dataset0-17.npz (27452, 7, 3584) (27452,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gnLGmEVqumA"
      },
      "source": [
        "**The model is created here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AtCVnFYMvxf",
        "outputId": "97f31c03-a9e0-4491-d64a-14223cf25c56"
      },
      "source": [
        "inputs = tf.keras.layers.Input(shape = (window, 3584)) #X_data.shape[0], X_data.shape[1]\n",
        "x1, x2, x3, x4 = tf.split(inputs, array_dims, axis = 2) # split inputs into given features for two consecutive shots\n",
        "print(x1.shape, x2.shape, x3.shape, x4.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 7, 2048) (None, 7, 512) (None, 7, 512) (None, 7, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZxW6QdiM9IJ"
      },
      "source": [
        "conv1 = tf.keras.Sequential()\n",
        "conv1.add(tf.keras.layers.Conv1D(filters = 24, kernel_size = 5, strides = 1, padding='same', activation='linear', \n",
        "kernel_initializer='lecun_normal', bias_initializer='lecun_normal', kernel_regularizer='l1', bias_regularizer='l1')) #1\n",
        "conv1.add(tf.keras.layers.BatchNormalization(axis=2))\n",
        "conv1.add(tf.keras.layers.ReLU())\n",
        "conv1.add(tf.keras.layers.GlobalAveragePooling1D()) #24\n",
        "\n",
        "conv2 = tf.keras.Sequential()\n",
        "conv2.add(tf.keras.layers.Conv1D(filters = 8, kernel_size = 5, strides = 1, padding='same', activation='linear', \n",
        "kernel_initializer='lecun_normal', bias_initializer='lecun_normal', kernel_regularizer='l1', bias_regularizer='l1')) #1\n",
        "conv2.add(tf.keras.layers.BatchNormalization(axis=2))\n",
        "conv2.add(tf.keras.layers.ReLU())\n",
        "conv2.add(tf.keras.layers.GlobalAveragePooling1D()) #8\n",
        "\n",
        "conv3 = tf.keras.Sequential()\n",
        "conv3.add(tf.keras.layers.Conv1D(filters = 8, kernel_size = 5, strides = 1, padding='same', activation='linear', \n",
        "kernel_initializer='lecun_normal', bias_initializer='lecun_normal', kernel_regularizer='l1', bias_regularizer='l1')) #1\n",
        "conv3.add(tf.keras.layers.BatchNormalization(axis=2))\n",
        "conv3.add(tf.keras.layers.ReLU())\n",
        "conv3.add(tf.keras.layers.GlobalAveragePooling1D()) #8\n",
        "\n",
        "conv4 = tf.keras.Sequential()\n",
        "conv4.add(tf.keras.layers.Conv1D(filters = 8, kernel_size = 5, strides = 1, padding='same', activation='linear', \n",
        "kernel_initializer='lecun_normal', bias_initializer='lecun_normal', kernel_regularizer='l1', bias_regularizer='l1')) #1\n",
        "conv4.add(tf.keras.layers.BatchNormalization(axis=2))\n",
        "conv4.add(tf.keras.layers.ReLU())\n",
        "conv4.add(tf.keras.layers.GlobalAveragePooling1D()) #8"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8_2AZgjM_v8"
      },
      "source": [
        "encode1 = conv1(x1)\n",
        "encode2 = conv2(x2)\n",
        "encode3 = conv3(x3)\n",
        "encode4 = conv4(x4)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2puFWhWNCH9",
        "outputId": "74c464df-c005-4239-aa35-673ff9b24c0b"
      },
      "source": [
        "shot1 = tf.keras.layers.Concatenate(axis = 1)([encode1, encode2, encode3, encode4])\n",
        "print(shot1.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmboVe32NES8"
      },
      "source": [
        "shot_d1 = tf.keras.layers.Dense(50, activation='linear', kernel_regularizer='l1', bias_regularizer='l1')(shot1)\n",
        "shot_r1 = tf.keras.layers.Dropout(0.4)(shot_d1)\n",
        "shot_b1 = tf.keras.layers.BatchNormalization(axis = 1)(shot_d1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQtkvQQANGW1"
      },
      "source": [
        "output = tf.keras.layers.Dense(1, activation = 'sigmoid')(shot_b1)\n",
        "model = tf.keras.Model(inputs = inputs, outputs = output)\n",
        "opt = tf.keras.optimizers.SGD(learning_rate = 0.001)\n",
        "model.compile(optimizer = opt, loss = BinaryFocalLoss(pos_weight = 9, gamma = 2.5), metrics=[tf.keras.losses.BinaryCrossentropy()]) #BinaryFocalLoss(pos_weight=7, gamma=4)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTmrdiGnNK2j",
        "outputId": "039dbb9a-1fb8-4e68-e354-701ea2bbf89a"
      },
      "source": [
        "model.summary()\n",
        "#tf.keras.utils.plot_model(model, to_file=image_out, dpi=100)\n",
        "\n",
        "training_log = '/content/drive/MyDrive/eluvio/' + '/' + 'separable_lasso2' + '.txt'\n",
        "print(training_log)\n",
        "csv_logger = tf.keras.callbacks.CSVLogger(training_log, append = True, separator=' ')\n",
        "metrics = model.fit(X1, Y1, epochs = 75, validation_split= 0.2, verbose=2, batch_size = 32, callbacks=[csv_logger])\n",
        "\n",
        "model_ID = '/content/drive/MyDrive/eluvio/test_model1.h5'\n",
        "print(model_ID)\n",
        "tf.keras.models.save_model(model, model_ID)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 7, 3584)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.split (TFOpLambda)           [(None, 7, 2048), (N 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 24)           245880      tf.split[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 8)            20520       tf.split[0][1]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 8)            20520       tf.split[0][2]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 8)            20520       tf.split[0][3]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 48)           0           sequential[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "                                                                 sequential_2[0][0]               \n",
            "                                                                 sequential_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 50)           2450        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 50)           200         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            51          batch_normalization_4[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 310,141\n",
            "Trainable params: 309,945\n",
            "Non-trainable params: 196\n",
            "__________________________________________________________________________________________________\n",
            "/content/drive/MyDrive/eluvio//separable_lasso2.txt\n",
            "Epoch 1/75\n",
            "687/687 - 42s - loss: 24.1401 - binary_crossentropy: 0.6727 - val_loss: 16.5930 - val_binary_crossentropy: 0.6603\n",
            "Epoch 2/75\n",
            "687/687 - 5s - loss: 11.8275 - binary_crossentropy: 0.6002 - val_loss: 8.8428 - val_binary_crossentropy: 0.3177\n",
            "Epoch 3/75\n",
            "687/687 - 5s - loss: 6.2618 - binary_crossentropy: 0.5846 - val_loss: 5.5298 - val_binary_crossentropy: 1.3983\n",
            "Epoch 4/75\n",
            "687/687 - 5s - loss: 4.2157 - binary_crossentropy: 0.5791 - val_loss: 3.6858 - val_binary_crossentropy: 0.3883\n",
            "Epoch 5/75\n",
            "687/687 - 5s - loss: 3.2454 - binary_crossentropy: 0.5736 - val_loss: 3.2658 - val_binary_crossentropy: 1.0134\n",
            "Epoch 6/75\n",
            "687/687 - 5s - loss: 2.7534 - binary_crossentropy: 0.5764 - val_loss: 3.4143 - val_binary_crossentropy: 0.2320\n",
            "Epoch 7/75\n",
            "687/687 - 5s - loss: 2.5156 - binary_crossentropy: 0.5811 - val_loss: 6.7117 - val_binary_crossentropy: 0.4879\n",
            "Epoch 8/75\n",
            "687/687 - 5s - loss: 2.3501 - binary_crossentropy: 0.5835 - val_loss: 3.3230 - val_binary_crossentropy: 1.8130\n",
            "Epoch 9/75\n",
            "687/687 - 5s - loss: 2.1917 - binary_crossentropy: 0.5858 - val_loss: 2.3495 - val_binary_crossentropy: 0.3784\n",
            "Epoch 10/75\n",
            "687/687 - 6s - loss: 2.0541 - binary_crossentropy: 0.5860 - val_loss: 6.4349 - val_binary_crossentropy: 0.5110\n",
            "Epoch 11/75\n",
            "687/687 - 5s - loss: 1.9249 - binary_crossentropy: 0.5866 - val_loss: 2.0797 - val_binary_crossentropy: 0.3059\n",
            "Epoch 12/75\n",
            "687/687 - 5s - loss: 1.7911 - binary_crossentropy: 0.5886 - val_loss: 2.0647 - val_binary_crossentropy: 0.2719\n",
            "Epoch 13/75\n",
            "687/687 - 5s - loss: 1.6731 - binary_crossentropy: 0.5886 - val_loss: 1.5844 - val_binary_crossentropy: 0.5150\n",
            "Epoch 14/75\n",
            "687/687 - 5s - loss: 1.5582 - binary_crossentropy: 0.5875 - val_loss: 2.6431 - val_binary_crossentropy: 0.2107\n",
            "Epoch 15/75\n",
            "687/687 - 5s - loss: 1.4464 - binary_crossentropy: 0.5883 - val_loss: 1.4093 - val_binary_crossentropy: 0.4662\n",
            "Epoch 16/75\n",
            "687/687 - 5s - loss: 1.3526 - binary_crossentropy: 0.5876 - val_loss: 1.3782 - val_binary_crossentropy: 0.7702\n",
            "Epoch 17/75\n",
            "687/687 - 5s - loss: 1.2315 - binary_crossentropy: 0.5892 - val_loss: 1.2289 - val_binary_crossentropy: 0.5555\n",
            "Epoch 18/75\n",
            "687/687 - 5s - loss: 1.1409 - binary_crossentropy: 0.5900 - val_loss: 1.0649 - val_binary_crossentropy: 0.6107\n",
            "Epoch 19/75\n",
            "687/687 - 5s - loss: 1.0457 - binary_crossentropy: 0.5900 - val_loss: 0.9950 - val_binary_crossentropy: 0.7402\n",
            "Epoch 20/75\n",
            "687/687 - 5s - loss: 0.9446 - binary_crossentropy: 0.5910 - val_loss: 0.9674 - val_binary_crossentropy: 0.6599\n",
            "Epoch 21/75\n",
            "687/687 - 5s - loss: 0.8616 - binary_crossentropy: 0.5907 - val_loss: 0.8296 - val_binary_crossentropy: 0.7368\n",
            "Epoch 22/75\n",
            "687/687 - 5s - loss: 0.7762 - binary_crossentropy: 0.5914 - val_loss: 0.9399 - val_binary_crossentropy: 0.8714\n",
            "Epoch 23/75\n",
            "687/687 - 5s - loss: 0.6915 - binary_crossentropy: 0.5908 - val_loss: 0.8093 - val_binary_crossentropy: 0.9432\n",
            "Epoch 24/75\n",
            "687/687 - 5s - loss: 0.6199 - binary_crossentropy: 0.5904 - val_loss: 0.5768 - val_binary_crossentropy: 0.5573\n",
            "Epoch 25/75\n",
            "687/687 - 5s - loss: 0.5625 - binary_crossentropy: 0.5898 - val_loss: 0.5450 - val_binary_crossentropy: 0.7189\n",
            "Epoch 26/75\n",
            "687/687 - 5s - loss: 0.5074 - binary_crossentropy: 0.5910 - val_loss: 0.5009 - val_binary_crossentropy: 0.7221\n",
            "Epoch 27/75\n",
            "687/687 - 5s - loss: 0.4564 - binary_crossentropy: 0.5896 - val_loss: 1.2076 - val_binary_crossentropy: 1.5639\n",
            "Epoch 28/75\n",
            "687/687 - 5s - loss: 0.4158 - binary_crossentropy: 0.5903 - val_loss: 0.6299 - val_binary_crossentropy: 0.2948\n",
            "Epoch 29/75\n",
            "687/687 - 5s - loss: 0.3787 - binary_crossentropy: 0.5901 - val_loss: 0.3966 - val_binary_crossentropy: 0.7659\n",
            "Epoch 30/75\n",
            "687/687 - 6s - loss: 0.3478 - binary_crossentropy: 0.5907 - val_loss: 0.8478 - val_binary_crossentropy: 1.2331\n",
            "Epoch 31/75\n",
            "687/687 - 5s - loss: 0.3191 - binary_crossentropy: 0.5901 - val_loss: 0.3109 - val_binary_crossentropy: 0.6772\n",
            "Epoch 32/75\n",
            "687/687 - 5s - loss: 0.2941 - binary_crossentropy: 0.5913 - val_loss: 0.5131 - val_binary_crossentropy: 1.0285\n",
            "Epoch 33/75\n",
            "687/687 - 5s - loss: 0.2747 - binary_crossentropy: 0.5912 - val_loss: 3.1127 - val_binary_crossentropy: 0.3392\n",
            "Epoch 34/75\n",
            "687/687 - 5s - loss: 0.2598 - binary_crossentropy: 0.5909 - val_loss: 0.3493 - val_binary_crossentropy: 0.3803\n",
            "Epoch 35/75\n",
            "687/687 - 5s - loss: 0.2486 - binary_crossentropy: 0.5926 - val_loss: 0.3742 - val_binary_crossentropy: 0.3598\n",
            "Epoch 36/75\n",
            "687/687 - 6s - loss: 0.2410 - binary_crossentropy: 0.5905 - val_loss: 0.3897 - val_binary_crossentropy: 0.9456\n",
            "Epoch 37/75\n",
            "687/687 - 5s - loss: 0.2387 - binary_crossentropy: 0.5918 - val_loss: 0.3853 - val_binary_crossentropy: 0.9208\n",
            "Epoch 38/75\n",
            "687/687 - 5s - loss: 0.2371 - binary_crossentropy: 0.5914 - val_loss: 0.2751 - val_binary_crossentropy: 0.7613\n",
            "Epoch 39/75\n",
            "687/687 - 5s - loss: 0.2344 - binary_crossentropy: 0.5914 - val_loss: 0.2572 - val_binary_crossentropy: 0.7303\n",
            "Epoch 40/75\n",
            "687/687 - 5s - loss: 0.2333 - binary_crossentropy: 0.5923 - val_loss: 0.3648 - val_binary_crossentropy: 0.3370\n",
            "Epoch 41/75\n",
            "687/687 - 5s - loss: 0.2329 - binary_crossentropy: 0.5924 - val_loss: 0.3554 - val_binary_crossentropy: 0.8966\n",
            "Epoch 42/75\n",
            "687/687 - 5s - loss: 0.2312 - binary_crossentropy: 0.5933 - val_loss: 0.2219 - val_binary_crossentropy: 0.5928\n",
            "Epoch 43/75\n",
            "687/687 - 5s - loss: 0.2289 - binary_crossentropy: 0.5920 - val_loss: 0.4143 - val_binary_crossentropy: 0.3172\n",
            "Epoch 44/75\n",
            "687/687 - 5s - loss: 0.2281 - binary_crossentropy: 0.5925 - val_loss: 0.2840 - val_binary_crossentropy: 0.7940\n",
            "Epoch 45/75\n",
            "687/687 - 5s - loss: 0.2273 - binary_crossentropy: 0.5899 - val_loss: 0.2294 - val_binary_crossentropy: 0.5574\n",
            "Epoch 46/75\n",
            "687/687 - 5s - loss: 0.2273 - binary_crossentropy: 0.5914 - val_loss: 0.2304 - val_binary_crossentropy: 0.5674\n",
            "Epoch 47/75\n",
            "687/687 - 5s - loss: 0.2262 - binary_crossentropy: 0.5910 - val_loss: 0.2292 - val_binary_crossentropy: 0.4906\n",
            "Epoch 48/75\n",
            "687/687 - 5s - loss: 0.2250 - binary_crossentropy: 0.5924 - val_loss: 0.3986 - val_binary_crossentropy: 0.3565\n",
            "Epoch 49/75\n",
            "687/687 - 5s - loss: 0.2248 - binary_crossentropy: 0.5925 - val_loss: 0.2238 - val_binary_crossentropy: 0.5208\n",
            "Epoch 50/75\n",
            "687/687 - 5s - loss: 0.2232 - binary_crossentropy: 0.5919 - val_loss: 0.2683 - val_binary_crossentropy: 0.7768\n",
            "Epoch 51/75\n",
            "687/687 - 5s - loss: 0.2229 - binary_crossentropy: 0.5920 - val_loss: 0.2480 - val_binary_crossentropy: 0.6913\n",
            "Epoch 52/75\n",
            "687/687 - 5s - loss: 0.2221 - binary_crossentropy: 0.5922 - val_loss: 0.2198 - val_binary_crossentropy: 0.6610\n",
            "Epoch 53/75\n",
            "687/687 - 5s - loss: 0.2202 - binary_crossentropy: 0.5914 - val_loss: 0.2469 - val_binary_crossentropy: 0.4609\n",
            "Epoch 54/75\n",
            "687/687 - 5s - loss: 0.2201 - binary_crossentropy: 0.5917 - val_loss: 0.2671 - val_binary_crossentropy: 0.7630\n",
            "Epoch 55/75\n",
            "687/687 - 5s - loss: 0.2203 - binary_crossentropy: 0.5920 - val_loss: 0.2181 - val_binary_crossentropy: 0.6263\n",
            "Epoch 56/75\n",
            "687/687 - 5s - loss: 0.2182 - binary_crossentropy: 0.5919 - val_loss: 0.3649 - val_binary_crossentropy: 0.9280\n",
            "Epoch 57/75\n",
            "687/687 - 5s - loss: 0.2183 - binary_crossentropy: 0.5919 - val_loss: 0.2134 - val_binary_crossentropy: 0.5502\n",
            "Epoch 58/75\n",
            "687/687 - 5s - loss: 0.2181 - binary_crossentropy: 0.5917 - val_loss: 0.2492 - val_binary_crossentropy: 0.4373\n",
            "Epoch 59/75\n",
            "687/687 - 5s - loss: 0.2179 - binary_crossentropy: 0.5914 - val_loss: 0.2821 - val_binary_crossentropy: 0.7803\n",
            "Epoch 60/75\n",
            "687/687 - 5s - loss: 0.2167 - binary_crossentropy: 0.5919 - val_loss: 0.2249 - val_binary_crossentropy: 0.5031\n",
            "Epoch 61/75\n",
            "687/687 - 5s - loss: 0.2179 - binary_crossentropy: 0.5927 - val_loss: 0.2114 - val_binary_crossentropy: 0.5487\n",
            "Epoch 62/75\n",
            "687/687 - 5s - loss: 0.2161 - binary_crossentropy: 0.5920 - val_loss: 0.4447 - val_binary_crossentropy: 0.3212\n",
            "Epoch 63/75\n",
            "687/687 - 5s - loss: 0.2164 - binary_crossentropy: 0.5916 - val_loss: 0.2126 - val_binary_crossentropy: 0.6435\n",
            "Epoch 64/75\n",
            "687/687 - 5s - loss: 0.2163 - binary_crossentropy: 0.5932 - val_loss: 0.6108 - val_binary_crossentropy: 0.2552\n",
            "Epoch 65/75\n",
            "687/687 - 5s - loss: 0.2164 - binary_crossentropy: 0.5911 - val_loss: 0.3251 - val_binary_crossentropy: 0.5137\n",
            "Epoch 66/75\n",
            "687/687 - 5s - loss: 0.2157 - binary_crossentropy: 0.5914 - val_loss: 0.2507 - val_binary_crossentropy: 0.7553\n",
            "Epoch 67/75\n",
            "687/687 - 5s - loss: 0.2156 - binary_crossentropy: 0.5919 - val_loss: 0.2349 - val_binary_crossentropy: 0.6435\n",
            "Epoch 68/75\n",
            "687/687 - 5s - loss: 0.2150 - binary_crossentropy: 0.5908 - val_loss: 0.4193 - val_binary_crossentropy: 0.9524\n",
            "Epoch 69/75\n",
            "687/687 - 6s - loss: 0.2154 - binary_crossentropy: 0.5913 - val_loss: 0.2123 - val_binary_crossentropy: 0.5315\n",
            "Epoch 70/75\n",
            "687/687 - 5s - loss: 0.2144 - binary_crossentropy: 0.5896 - val_loss: 0.3475 - val_binary_crossentropy: 0.9182\n",
            "Epoch 71/75\n",
            "687/687 - 5s - loss: 0.2143 - binary_crossentropy: 0.5898 - val_loss: 0.2607 - val_binary_crossentropy: 0.7408\n",
            "Epoch 72/75\n",
            "687/687 - 5s - loss: 0.2148 - binary_crossentropy: 0.5897 - val_loss: 0.2649 - val_binary_crossentropy: 0.7837\n",
            "Epoch 73/75\n",
            "687/687 - 5s - loss: 0.2152 - binary_crossentropy: 0.5916 - val_loss: 0.3581 - val_binary_crossentropy: 0.3638\n",
            "Epoch 74/75\n",
            "687/687 - 5s - loss: 0.2142 - binary_crossentropy: 0.5915 - val_loss: 0.2549 - val_binary_crossentropy: 0.7362\n",
            "Epoch 75/75\n",
            "687/687 - 5s - loss: 0.2138 - binary_crossentropy: 0.5922 - val_loss: 0.2149 - val_binary_crossentropy: 0.5184\n",
            "/content/drive/MyDrive/eluvio/test_model1.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fItTt-H-NSAD",
        "outputId": "283dda92-a7e6-4a2b-d28d-b82f3f4aeaad"
      },
      "source": [
        "filename2 = '/content/drive/MyDrive/eluvio/datasets/dataset18-34.npz'\n",
        "loaded2 = np.load(filename2)\n",
        "X2 = loaded2['a']\n",
        "Y2 = loaded2['b']\n",
        "print(filename2, X2.shape, Y2.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/eluvio/datasets/dataset18-34.npz (27018, 7, 3584) (27018,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74_qQPXjq2s-"
      },
      "source": [
        "window = 7 # Window needs to be an int greater than 1 and odd!\n",
        "first = int((window - 1)/2)\n",
        "array_dims = np.zeros((4), dtype = np.int32)\n",
        "array_dims[0] = 2048\n",
        "array_dims[1] = 512 #feat1_size + feat2_size\n",
        "array_dims[2] = 512 #feat1_size + feat2_size + feat3_size\n",
        "array_dims[3] = 512 #feat1_size + feat2_size + feat3_size + feat4_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgdRNYEoR4NN",
        "outputId": "f9605f1a-6621-467d-e617-e2f14ae1958e"
      },
      "source": [
        "model=tf.keras.models.load_model('/content/drive/MyDrive/eluvio/test_model1.h5',compile=False)\n",
        "model.summary()\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate = 0.001)\n",
        "model.compile(optimizer = opt, loss = BinaryFocalLoss(pos_weight = 9, gamma = 2.5), metrics=[tf.keras.losses.BinaryCrossentropy()]) #BinaryFocalLoss(pos_weight=7, gamma=4)\n",
        "\n",
        "training_log = '/content/drive/MyDrive/eluvio/' + '/' + 'separable_lasso2' + '.txt'\n",
        "print(training_log)\n",
        "csv_logger = tf.keras.callbacks.CSVLogger(training_log, append = True, separator=' ')\n",
        "\n",
        "metrics = model.fit(X2, Y2, epochs = 75, validation_split= 0.2, verbose=2, batch_size = 32, callbacks=[csv_logger])\n",
        "model_ID = '/content/drive/MyDrive/eluvio/test_model12.h5'\n",
        "print(model_ID)\n",
        "tf.keras.models.save_model(model,model_ID)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 7, 3584)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.split (TFOpLambda)           [(None, 7, 2048), (N 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 24)           245880      tf.split[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 8)            20520       tf.split[0][1]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 8)            20520       tf.split[0][2]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 8)            20520       tf.split[0][3]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 48)           0           sequential[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "                                                                 sequential_2[0][0]               \n",
            "                                                                 sequential_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 50)           2450        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 50)           200         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            51          batch_normalization_4[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 310,141\n",
            "Trainable params: 309,945\n",
            "Non-trainable params: 196\n",
            "__________________________________________________________________________________________________\n",
            "/content/drive/MyDrive/eluvio//separable_lasso2.txt\n",
            "Epoch 1/75\n",
            "676/676 - 19s - loss: 0.2295 - binary_crossentropy: 0.5995 - val_loss: 0.2121 - val_binary_crossentropy: 0.5157\n",
            "Epoch 2/75\n",
            "676/676 - 5s - loss: 0.2267 - binary_crossentropy: 0.6047 - val_loss: 0.2106 - val_binary_crossentropy: 0.5735\n",
            "Epoch 3/75\n",
            "676/676 - 5s - loss: 0.2260 - binary_crossentropy: 0.6084 - val_loss: 0.2790 - val_binary_crossentropy: 0.4121\n",
            "Epoch 4/75\n",
            "676/676 - 5s - loss: 0.2245 - binary_crossentropy: 0.6103 - val_loss: 0.2203 - val_binary_crossentropy: 0.6654\n",
            "Epoch 5/75\n",
            "676/676 - 5s - loss: 0.2242 - binary_crossentropy: 0.6106 - val_loss: 0.3815 - val_binary_crossentropy: 0.3327\n",
            "Epoch 6/75\n",
            "676/676 - 5s - loss: 0.2250 - binary_crossentropy: 0.6110 - val_loss: 0.2131 - val_binary_crossentropy: 0.6678\n",
            "Epoch 7/75\n",
            "676/676 - 5s - loss: 0.2232 - binary_crossentropy: 0.6111 - val_loss: 0.3385 - val_binary_crossentropy: 0.9027\n",
            "Epoch 8/75\n",
            "676/676 - 5s - loss: 0.2241 - binary_crossentropy: 0.6109 - val_loss: 0.3849 - val_binary_crossentropy: 0.3508\n",
            "Epoch 9/75\n",
            "676/676 - 5s - loss: 0.2240 - binary_crossentropy: 0.6110 - val_loss: 0.2112 - val_binary_crossentropy: 0.6020\n",
            "Epoch 10/75\n",
            "676/676 - 5s - loss: 0.2246 - binary_crossentropy: 0.6103 - val_loss: 0.2038 - val_binary_crossentropy: 0.5691\n",
            "Epoch 11/75\n",
            "676/676 - 5s - loss: 0.2241 - binary_crossentropy: 0.6111 - val_loss: 0.2097 - val_binary_crossentropy: 0.5763\n",
            "Epoch 12/75\n",
            "676/676 - 5s - loss: 0.2232 - binary_crossentropy: 0.6110 - val_loss: 0.2203 - val_binary_crossentropy: 0.6724\n",
            "Epoch 13/75\n",
            "676/676 - 5s - loss: 0.2230 - binary_crossentropy: 0.6095 - val_loss: 0.2361 - val_binary_crossentropy: 0.7315\n",
            "Epoch 14/75\n",
            "676/676 - 5s - loss: 0.2242 - binary_crossentropy: 0.6094 - val_loss: 0.2102 - val_binary_crossentropy: 0.5216\n",
            "Epoch 15/75\n",
            "676/676 - 5s - loss: 0.2232 - binary_crossentropy: 0.6121 - val_loss: 0.2681 - val_binary_crossentropy: 0.4257\n",
            "Epoch 16/75\n",
            "676/676 - 5s - loss: 0.2236 - binary_crossentropy: 0.6120 - val_loss: 0.2083 - val_binary_crossentropy: 0.6195\n",
            "Epoch 17/75\n",
            "676/676 - 5s - loss: 0.2243 - binary_crossentropy: 0.6123 - val_loss: 0.4766 - val_binary_crossentropy: 1.0840\n",
            "Epoch 18/75\n",
            "676/676 - 5s - loss: 0.2229 - binary_crossentropy: 0.6110 - val_loss: 0.2452 - val_binary_crossentropy: 0.7559\n",
            "Epoch 19/75\n",
            "676/676 - 5s - loss: 0.2233 - binary_crossentropy: 0.6110 - val_loss: 0.2141 - val_binary_crossentropy: 0.5549\n",
            "Epoch 20/75\n",
            "676/676 - 5s - loss: 0.2234 - binary_crossentropy: 0.6103 - val_loss: 0.2136 - val_binary_crossentropy: 0.5602\n",
            "Epoch 21/75\n",
            "676/676 - 6s - loss: 0.2236 - binary_crossentropy: 0.6109 - val_loss: 0.2201 - val_binary_crossentropy: 0.5928\n",
            "Epoch 22/75\n",
            "676/676 - 5s - loss: 0.2227 - binary_crossentropy: 0.6120 - val_loss: 0.2115 - val_binary_crossentropy: 0.6522\n",
            "Epoch 23/75\n",
            "676/676 - 5s - loss: 0.2229 - binary_crossentropy: 0.6112 - val_loss: 0.2136 - val_binary_crossentropy: 0.5258\n",
            "Epoch 24/75\n",
            "676/676 - 5s - loss: 0.2231 - binary_crossentropy: 0.6097 - val_loss: 0.2410 - val_binary_crossentropy: 0.7413\n",
            "Epoch 25/75\n",
            "676/676 - 5s - loss: 0.2234 - binary_crossentropy: 0.6104 - val_loss: 0.2186 - val_binary_crossentropy: 0.6736\n",
            "Epoch 26/75\n",
            "676/676 - 5s - loss: 0.2239 - binary_crossentropy: 0.6110 - val_loss: 0.3449 - val_binary_crossentropy: 0.3470\n",
            "Epoch 27/75\n",
            "676/676 - 5s - loss: 0.2230 - binary_crossentropy: 0.6111 - val_loss: 0.2026 - val_binary_crossentropy: 0.5629\n",
            "Epoch 28/75\n",
            "676/676 - 5s - loss: 0.2232 - binary_crossentropy: 0.6098 - val_loss: 0.3302 - val_binary_crossentropy: 0.3658\n",
            "Epoch 29/75\n",
            "676/676 - 5s - loss: 0.2235 - binary_crossentropy: 0.6100 - val_loss: 0.2232 - val_binary_crossentropy: 0.6951\n",
            "Epoch 30/75\n",
            "676/676 - 5s - loss: 0.2233 - binary_crossentropy: 0.6093 - val_loss: 0.2281 - val_binary_crossentropy: 0.6978\n",
            "Epoch 31/75\n",
            "676/676 - 5s - loss: 0.2234 - binary_crossentropy: 0.6098 - val_loss: 0.2109 - val_binary_crossentropy: 0.6332\n",
            "Epoch 32/75\n",
            "676/676 - 5s - loss: 0.2231 - binary_crossentropy: 0.6087 - val_loss: 0.2086 - val_binary_crossentropy: 0.5453\n",
            "Epoch 33/75\n",
            "676/676 - 5s - loss: 0.2234 - binary_crossentropy: 0.6092 - val_loss: 0.3536 - val_binary_crossentropy: 0.9433\n",
            "Epoch 34/75\n",
            "676/676 - 5s - loss: 0.2226 - binary_crossentropy: 0.6098 - val_loss: 0.2328 - val_binary_crossentropy: 0.4602\n",
            "Epoch 35/75\n",
            "676/676 - 5s - loss: 0.2236 - binary_crossentropy: 0.6104 - val_loss: 0.2052 - val_binary_crossentropy: 0.5242\n",
            "Epoch 36/75\n",
            "676/676 - 5s - loss: 0.2233 - binary_crossentropy: 0.6093 - val_loss: 0.2641 - val_binary_crossentropy: 0.4277\n",
            "Epoch 37/75\n",
            "676/676 - 5s - loss: 0.2233 - binary_crossentropy: 0.6097 - val_loss: 0.2126 - val_binary_crossentropy: 0.5190\n",
            "Epoch 38/75\n",
            "676/676 - 5s - loss: 0.2233 - binary_crossentropy: 0.6096 - val_loss: 0.2280 - val_binary_crossentropy: 0.7173\n",
            "Epoch 39/75\n",
            "676/676 - 5s - loss: 0.2233 - binary_crossentropy: 0.6099 - val_loss: 0.2159 - val_binary_crossentropy: 0.6500\n",
            "Epoch 40/75\n",
            "676/676 - 5s - loss: 0.2237 - binary_crossentropy: 0.6102 - val_loss: 0.2574 - val_binary_crossentropy: 0.7719\n",
            "Epoch 41/75\n",
            "676/676 - 5s - loss: 0.2238 - binary_crossentropy: 0.6104 - val_loss: 0.4673 - val_binary_crossentropy: 0.2980\n",
            "Epoch 42/75\n",
            "676/676 - 5s - loss: 0.2219 - binary_crossentropy: 0.6098 - val_loss: 0.2327 - val_binary_crossentropy: 0.7194\n",
            "Epoch 43/75\n",
            "676/676 - 5s - loss: 0.2231 - binary_crossentropy: 0.6082 - val_loss: 0.4345 - val_binary_crossentropy: 1.0423\n",
            "Epoch 44/75\n",
            "676/676 - 5s - loss: 0.2232 - binary_crossentropy: 0.6094 - val_loss: 0.2460 - val_binary_crossentropy: 0.4649\n",
            "Epoch 45/75\n",
            "676/676 - 5s - loss: 0.2238 - binary_crossentropy: 0.6091 - val_loss: 0.2949 - val_binary_crossentropy: 0.8247\n",
            "Epoch 46/75\n",
            "676/676 - 5s - loss: 0.2243 - binary_crossentropy: 0.6110 - val_loss: 0.2733 - val_binary_crossentropy: 0.8225\n",
            "Epoch 47/75\n",
            "676/676 - 5s - loss: 0.2226 - binary_crossentropy: 0.6092 - val_loss: 0.5565 - val_binary_crossentropy: 0.2768\n",
            "Epoch 48/75\n",
            "676/676 - 5s - loss: 0.2239 - binary_crossentropy: 0.6095 - val_loss: 0.2131 - val_binary_crossentropy: 0.6293\n",
            "Epoch 49/75\n",
            "676/676 - 5s - loss: 0.2229 - binary_crossentropy: 0.6104 - val_loss: 0.2713 - val_binary_crossentropy: 0.8060\n",
            "Epoch 50/75\n",
            "676/676 - 5s - loss: 0.2234 - binary_crossentropy: 0.6109 - val_loss: 0.4181 - val_binary_crossentropy: 0.3321\n",
            "Epoch 51/75\n",
            "676/676 - 5s - loss: 0.2231 - binary_crossentropy: 0.6105 - val_loss: 0.2891 - val_binary_crossentropy: 0.3935\n",
            "Epoch 52/75\n",
            "676/676 - 5s - loss: 0.2229 - binary_crossentropy: 0.6100 - val_loss: 0.4766 - val_binary_crossentropy: 0.2984\n",
            "Epoch 53/75\n",
            "676/676 - 5s - loss: 0.2233 - binary_crossentropy: 0.6107 - val_loss: 0.2331 - val_binary_crossentropy: 0.7194\n",
            "Epoch 54/75\n",
            "676/676 - 5s - loss: 0.2235 - binary_crossentropy: 0.6104 - val_loss: 0.2420 - val_binary_crossentropy: 0.7527\n",
            "Epoch 55/75\n",
            "676/676 - 5s - loss: 0.2228 - binary_crossentropy: 0.6103 - val_loss: 0.3044 - val_binary_crossentropy: 0.8722\n",
            "Epoch 56/75\n",
            "676/676 - 5s - loss: 0.2220 - binary_crossentropy: 0.6093 - val_loss: 0.2168 - val_binary_crossentropy: 0.6484\n",
            "Epoch 57/75\n",
            "676/676 - 5s - loss: 0.2238 - binary_crossentropy: 0.6087 - val_loss: 0.2184 - val_binary_crossentropy: 0.4888\n",
            "Epoch 58/75\n",
            "676/676 - 5s - loss: 0.2227 - binary_crossentropy: 0.6083 - val_loss: 0.2845 - val_binary_crossentropy: 0.8389\n",
            "Epoch 59/75\n",
            "676/676 - 5s - loss: 0.2245 - binary_crossentropy: 0.6090 - val_loss: 0.3152 - val_binary_crossentropy: 0.3726\n",
            "Epoch 60/75\n",
            "676/676 - 5s - loss: 0.2226 - binary_crossentropy: 0.6091 - val_loss: 0.2179 - val_binary_crossentropy: 0.6691\n",
            "Epoch 61/75\n",
            "676/676 - 5s - loss: 0.2230 - binary_crossentropy: 0.6085 - val_loss: 0.3769 - val_binary_crossentropy: 0.9581\n",
            "Epoch 62/75\n",
            "676/676 - 5s - loss: 0.2236 - binary_crossentropy: 0.6098 - val_loss: 0.2095 - val_binary_crossentropy: 0.6145\n",
            "Epoch 63/75\n",
            "676/676 - 5s - loss: 0.2227 - binary_crossentropy: 0.6089 - val_loss: 0.2174 - val_binary_crossentropy: 0.6665\n",
            "Epoch 64/75\n",
            "676/676 - 6s - loss: 0.2228 - binary_crossentropy: 0.6090 - val_loss: 0.2243 - val_binary_crossentropy: 0.5023\n",
            "Epoch 65/75\n",
            "676/676 - 6s - loss: 0.2230 - binary_crossentropy: 0.6077 - val_loss: 0.2783 - val_binary_crossentropy: 0.4264\n",
            "Epoch 66/75\n",
            "676/676 - 5s - loss: 0.2223 - binary_crossentropy: 0.6061 - val_loss: 0.2370 - val_binary_crossentropy: 0.4702\n",
            "Epoch 67/75\n",
            "676/676 - 5s - loss: 0.2237 - binary_crossentropy: 0.6073 - val_loss: 0.2402 - val_binary_crossentropy: 0.4430\n",
            "Epoch 68/75\n",
            "676/676 - 5s - loss: 0.2229 - binary_crossentropy: 0.6071 - val_loss: 0.2052 - val_binary_crossentropy: 0.5590\n",
            "Epoch 69/75\n",
            "676/676 - 5s - loss: 0.2233 - binary_crossentropy: 0.6081 - val_loss: 0.2325 - val_binary_crossentropy: 0.6304\n",
            "Epoch 70/75\n",
            "676/676 - 5s - loss: 0.2231 - binary_crossentropy: 0.6085 - val_loss: 0.2427 - val_binary_crossentropy: 0.4592\n",
            "Epoch 71/75\n",
            "676/676 - 5s - loss: 0.2229 - binary_crossentropy: 0.6082 - val_loss: 0.2297 - val_binary_crossentropy: 0.7036\n",
            "Epoch 72/75\n",
            "676/676 - 5s - loss: 0.2237 - binary_crossentropy: 0.6077 - val_loss: 0.2309 - val_binary_crossentropy: 0.5816\n",
            "Epoch 73/75\n",
            "676/676 - 5s - loss: 0.2237 - binary_crossentropy: 0.6081 - val_loss: 0.2218 - val_binary_crossentropy: 0.4778\n",
            "Epoch 74/75\n",
            "676/676 - 5s - loss: 0.2227 - binary_crossentropy: 0.6069 - val_loss: 0.2603 - val_binary_crossentropy: 0.7875\n",
            "Epoch 75/75\n",
            "676/676 - 5s - loss: 0.2235 - binary_crossentropy: 0.6069 - val_loss: 0.2157 - val_binary_crossentropy: 0.6508\n",
            "/content/drive/MyDrive/eluvio/test_model12.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "johlXBkFq-aU"
      },
      "source": [
        "window = 7 # Window needs to be an int greater than 1 and odd!\n",
        "first = int((window - 1)/2)\n",
        "array_dims = np.zeros((4), dtype = np.int32)\n",
        "array_dims[0] = 2048\n",
        "array_dims[1] = 512 #feat1_size + feat2_size\n",
        "array_dims[2] = 512 #feat1_size + feat2_size + feat3_size\n",
        "array_dims[3] = 512 #feat1_size + feat2_size + feat3_size + feat4_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlJh-js2S3UK"
      },
      "source": [
        "filename3 = '/content/drive/MyDrive/eluvio/datasets/dataset35-50.npz'\n",
        "loaded3 = np.load(filename3)\n",
        "X3 = loaded3['a']\n",
        "Y3 = loaded3['b']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQBtHBHeXZ-j",
        "outputId": "16e9cf0b-e2e2-45b7-d4d1-2657b1e76341"
      },
      "source": [
        "model=tf.keras.models.load_model('/content/drive/MyDrive/eluvio/test_model12.h5',compile=False)\n",
        "model.summary()\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate = 0.001)\n",
        "model.compile(optimizer = opt, loss = BinaryFocalLoss(pos_weight = 9, gamma = 2.5), metrics=[tf.keras.losses.BinaryCrossentropy()]) #BinaryFocalLoss(pos_weight=7, gamma=4)\n",
        "\n",
        "training_log = '/content/drive/MyDrive/eluvio/' + '/' + 'separable_lasso2' + '.txt'\n",
        "print(training_log)\n",
        "csv_logger = tf.keras.callbacks.CSVLogger(training_log, append = True, separator=' ')\n",
        "\n",
        "metrics = model.fit(X3, Y3, epochs = 75, validation_split= 0.2, verbose=2, batch_size = 25, callbacks=[csv_logger])\n",
        "model_ID = '/content/drive/MyDrive/eluvio/test_model3.h5'\n",
        "print(model_ID)\n",
        "tf.keras.models.save_model(model,model_ID)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 7, 3584)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.split (TFOpLambda)           [(None, 7, 2048), (N 0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 24)           245880      tf.split[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, 8)            20520       tf.split[0][1]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 8)            20520       tf.split[0][2]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_3 (Sequential)       (None, 8)            20520       tf.split[0][3]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 48)           0           sequential[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "                                                                 sequential_2[0][0]               \n",
            "                                                                 sequential_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 50)           2450        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 50)           200         dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            51          batch_normalization_4[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 310,141\n",
            "Trainable params: 309,945\n",
            "Non-trainable params: 196\n",
            "__________________________________________________________________________________________________\n",
            "/content/drive/MyDrive/eluvio//separable_lasso2.txt\n",
            "Epoch 1/75\n",
            "925/925 - 43s - loss: 0.2200 - binary_crossentropy: 0.6091 - val_loss: 0.2494 - val_binary_crossentropy: 0.6145\n",
            "Epoch 2/75\n",
            "925/925 - 8s - loss: 0.2169 - binary_crossentropy: 0.6066 - val_loss: 0.3690 - val_binary_crossentropy: 0.4697\n",
            "Epoch 3/75\n",
            "925/925 - 8s - loss: 0.2173 - binary_crossentropy: 0.6079 - val_loss: 0.2558 - val_binary_crossentropy: 0.6696\n",
            "Epoch 4/75\n",
            "925/925 - 8s - loss: 0.2159 - binary_crossentropy: 0.6088 - val_loss: 0.2448 - val_binary_crossentropy: 0.6363\n",
            "Epoch 5/75\n",
            "925/925 - 8s - loss: 0.2165 - binary_crossentropy: 0.6089 - val_loss: 0.2421 - val_binary_crossentropy: 0.6157\n",
            "Epoch 6/75\n",
            "925/925 - 8s - loss: 0.2147 - binary_crossentropy: 0.6078 - val_loss: 0.2923 - val_binary_crossentropy: 0.5074\n",
            "Epoch 7/75\n",
            "925/925 - 8s - loss: 0.2141 - binary_crossentropy: 0.6067 - val_loss: 0.2591 - val_binary_crossentropy: 0.7195\n",
            "Epoch 8/75\n",
            "925/925 - 8s - loss: 0.2132 - binary_crossentropy: 0.6083 - val_loss: 0.2846 - val_binary_crossentropy: 0.8155\n",
            "Epoch 9/75\n",
            "925/925 - 8s - loss: 0.2101 - binary_crossentropy: 0.6075 - val_loss: 0.2496 - val_binary_crossentropy: 0.7171\n",
            "Epoch 10/75\n",
            "925/925 - 8s - loss: 0.2099 - binary_crossentropy: 0.6072 - val_loss: 0.2400 - val_binary_crossentropy: 0.6910\n",
            "Epoch 11/75\n",
            "925/925 - 8s - loss: 0.2103 - binary_crossentropy: 0.6075 - val_loss: 0.2434 - val_binary_crossentropy: 0.7057\n",
            "Epoch 12/75\n",
            "925/925 - 8s - loss: 0.2100 - binary_crossentropy: 0.6071 - val_loss: 0.2519 - val_binary_crossentropy: 0.5664\n",
            "Epoch 13/75\n",
            "925/925 - 8s - loss: 0.2096 - binary_crossentropy: 0.6055 - val_loss: 0.2558 - val_binary_crossentropy: 0.5667\n",
            "Epoch 14/75\n",
            "925/925 - 8s - loss: 0.2097 - binary_crossentropy: 0.6069 - val_loss: 0.2437 - val_binary_crossentropy: 0.6016\n",
            "Epoch 15/75\n",
            "925/925 - 8s - loss: 0.2094 - binary_crossentropy: 0.6069 - val_loss: 0.2358 - val_binary_crossentropy: 0.6414\n",
            "Epoch 16/75\n",
            "925/925 - 8s - loss: 0.2094 - binary_crossentropy: 0.6047 - val_loss: 0.2425 - val_binary_crossentropy: 0.6525\n",
            "Epoch 17/75\n",
            "925/925 - 8s - loss: 0.2099 - binary_crossentropy: 0.6066 - val_loss: 0.6954 - val_binary_crossentropy: 1.2339\n",
            "Epoch 18/75\n",
            "925/925 - 8s - loss: 0.2121 - binary_crossentropy: 0.6083 - val_loss: 0.2393 - val_binary_crossentropy: 0.6721\n",
            "Epoch 19/75\n",
            "925/925 - 8s - loss: 0.2092 - binary_crossentropy: 0.6077 - val_loss: 0.2401 - val_binary_crossentropy: 0.7151\n",
            "Epoch 20/75\n",
            "925/925 - 8s - loss: 0.2102 - binary_crossentropy: 0.6061 - val_loss: 0.2439 - val_binary_crossentropy: 0.5970\n",
            "Epoch 21/75\n",
            "925/925 - 8s - loss: 0.2087 - binary_crossentropy: 0.6075 - val_loss: 0.2577 - val_binary_crossentropy: 0.5792\n",
            "Epoch 22/75\n",
            "925/925 - 8s - loss: 0.2096 - binary_crossentropy: 0.6054 - val_loss: 0.2363 - val_binary_crossentropy: 0.6719\n",
            "Epoch 23/75\n",
            "925/925 - 8s - loss: 0.2087 - binary_crossentropy: 0.6053 - val_loss: 0.2369 - val_binary_crossentropy: 0.6284\n",
            "Epoch 24/75\n",
            "925/925 - 8s - loss: 0.2097 - binary_crossentropy: 0.6057 - val_loss: 0.2386 - val_binary_crossentropy: 0.6054\n",
            "Epoch 25/75\n",
            "925/925 - 8s - loss: 0.2105 - binary_crossentropy: 0.6050 - val_loss: 0.2429 - val_binary_crossentropy: 0.5813\n",
            "Epoch 26/75\n",
            "925/925 - 8s - loss: 0.2093 - binary_crossentropy: 0.6067 - val_loss: 0.2327 - val_binary_crossentropy: 0.6134\n",
            "Epoch 27/75\n",
            "925/925 - 8s - loss: 0.2103 - binary_crossentropy: 0.6057 - val_loss: 0.2844 - val_binary_crossentropy: 0.5248\n",
            "Epoch 28/75\n",
            "925/925 - 8s - loss: 0.2097 - binary_crossentropy: 0.6072 - val_loss: 0.2450 - val_binary_crossentropy: 0.6551\n",
            "Epoch 29/75\n",
            "925/925 - 8s - loss: 0.2099 - binary_crossentropy: 0.6054 - val_loss: 0.2458 - val_binary_crossentropy: 0.6140\n",
            "Epoch 30/75\n",
            "925/925 - 8s - loss: 0.2104 - binary_crossentropy: 0.6060 - val_loss: 0.2420 - val_binary_crossentropy: 0.5997\n",
            "Epoch 31/75\n",
            "925/925 - 8s - loss: 0.2096 - binary_crossentropy: 0.6071 - val_loss: 0.3682 - val_binary_crossentropy: 0.9350\n",
            "Epoch 32/75\n",
            "925/925 - 8s - loss: 0.2100 - binary_crossentropy: 0.6067 - val_loss: 0.2412 - val_binary_crossentropy: 0.6441\n",
            "Epoch 33/75\n",
            "925/925 - 8s - loss: 0.2089 - binary_crossentropy: 0.6050 - val_loss: 0.2665 - val_binary_crossentropy: 0.7727\n",
            "Epoch 34/75\n",
            "925/925 - 8s - loss: 0.2098 - binary_crossentropy: 0.6058 - val_loss: 0.2391 - val_binary_crossentropy: 0.6710\n",
            "Epoch 35/75\n",
            "925/925 - 8s - loss: 0.2088 - binary_crossentropy: 0.6051 - val_loss: 0.2432 - val_binary_crossentropy: 0.6023\n",
            "Epoch 36/75\n",
            "925/925 - 8s - loss: 0.2100 - binary_crossentropy: 0.6054 - val_loss: 0.2809 - val_binary_crossentropy: 0.5285\n",
            "Epoch 37/75\n",
            "925/925 - 8s - loss: 0.2090 - binary_crossentropy: 0.6072 - val_loss: 0.2597 - val_binary_crossentropy: 0.5568\n",
            "Epoch 38/75\n",
            "925/925 - 8s - loss: 0.2097 - binary_crossentropy: 0.6041 - val_loss: 0.2532 - val_binary_crossentropy: 0.5539\n",
            "Epoch 39/75\n",
            "925/925 - 8s - loss: 0.2101 - binary_crossentropy: 0.6046 - val_loss: 0.2365 - val_binary_crossentropy: 0.6527\n",
            "Epoch 40/75\n",
            "925/925 - 8s - loss: 0.2088 - binary_crossentropy: 0.6059 - val_loss: 0.3179 - val_binary_crossentropy: 0.8542\n",
            "Epoch 41/75\n",
            "925/925 - 8s - loss: 0.2097 - binary_crossentropy: 0.6033 - val_loss: 0.3503 - val_binary_crossentropy: 0.5566\n",
            "Epoch 42/75\n",
            "925/925 - 8s - loss: 0.2104 - binary_crossentropy: 0.6042 - val_loss: 0.2397 - val_binary_crossentropy: 0.6727\n",
            "Epoch 43/75\n",
            "925/925 - 8s - loss: 0.2092 - binary_crossentropy: 0.6063 - val_loss: 0.2624 - val_binary_crossentropy: 0.7391\n",
            "Epoch 44/75\n",
            "925/925 - 8s - loss: 0.2103 - binary_crossentropy: 0.6056 - val_loss: 0.2912 - val_binary_crossentropy: 0.5309\n",
            "Epoch 45/75\n",
            "925/925 - 8s - loss: 0.2102 - binary_crossentropy: 0.6064 - val_loss: 0.2576 - val_binary_crossentropy: 0.7362\n",
            "Epoch 46/75\n",
            "925/925 - 8s - loss: 0.2093 - binary_crossentropy: 0.6064 - val_loss: 0.2349 - val_binary_crossentropy: 0.6178\n",
            "Epoch 47/75\n",
            "925/925 - 8s - loss: 0.2097 - binary_crossentropy: 0.6047 - val_loss: 0.5641 - val_binary_crossentropy: 1.0823\n",
            "Epoch 48/75\n",
            "925/925 - 8s - loss: 0.2112 - binary_crossentropy: 0.6070 - val_loss: 0.2744 - val_binary_crossentropy: 0.5469\n",
            "Epoch 49/75\n",
            "925/925 - 8s - loss: 0.2090 - binary_crossentropy: 0.6064 - val_loss: 0.2517 - val_binary_crossentropy: 0.6939\n",
            "Epoch 50/75\n",
            "925/925 - 8s - loss: 0.2105 - binary_crossentropy: 0.6049 - val_loss: 0.2725 - val_binary_crossentropy: 0.5450\n",
            "Epoch 51/75\n",
            "925/925 - 8s - loss: 0.2096 - binary_crossentropy: 0.6046 - val_loss: 0.2844 - val_binary_crossentropy: 0.7984\n",
            "Epoch 52/75\n",
            "925/925 - 8s - loss: 0.2099 - binary_crossentropy: 0.6065 - val_loss: 0.2357 - val_binary_crossentropy: 0.6434\n",
            "Epoch 53/75\n",
            "925/925 - 8s - loss: 0.2104 - binary_crossentropy: 0.6056 - val_loss: 0.2445 - val_binary_crossentropy: 0.6054\n",
            "Epoch 54/75\n",
            "925/925 - 8s - loss: 0.2095 - binary_crossentropy: 0.6059 - val_loss: 0.2501 - val_binary_crossentropy: 0.5819\n",
            "Epoch 55/75\n",
            "925/925 - 8s - loss: 0.2102 - binary_crossentropy: 0.6067 - val_loss: 0.2611 - val_binary_crossentropy: 0.5550\n",
            "Epoch 56/75\n",
            "925/925 - 8s - loss: 0.2095 - binary_crossentropy: 0.6079 - val_loss: 0.4225 - val_binary_crossentropy: 0.4485\n",
            "Epoch 57/75\n",
            "925/925 - 8s - loss: 0.2099 - binary_crossentropy: 0.6065 - val_loss: 0.2862 - val_binary_crossentropy: 0.8119\n",
            "Epoch 58/75\n",
            "925/925 - 8s - loss: 0.2099 - binary_crossentropy: 0.6064 - val_loss: 0.2405 - val_binary_crossentropy: 0.5915\n",
            "Epoch 59/75\n",
            "925/925 - 8s - loss: 0.2093 - binary_crossentropy: 0.6062 - val_loss: 0.2483 - val_binary_crossentropy: 0.5974\n",
            "Epoch 60/75\n",
            "925/925 - 8s - loss: 0.2098 - binary_crossentropy: 0.6055 - val_loss: 0.2467 - val_binary_crossentropy: 0.6054\n",
            "Epoch 61/75\n",
            "925/925 - 8s - loss: 0.2100 - binary_crossentropy: 0.6050 - val_loss: 0.2467 - val_binary_crossentropy: 0.7134\n",
            "Epoch 62/75\n",
            "925/925 - 8s - loss: 0.2097 - binary_crossentropy: 0.6059 - val_loss: 0.2956 - val_binary_crossentropy: 0.5165\n",
            "Epoch 63/75\n",
            "925/925 - 8s - loss: 0.2101 - binary_crossentropy: 0.6053 - val_loss: 0.2461 - val_binary_crossentropy: 0.6822\n",
            "Epoch 64/75\n",
            "925/925 - 9s - loss: 0.2099 - binary_crossentropy: 0.6067 - val_loss: 0.2630 - val_binary_crossentropy: 0.5460\n",
            "Epoch 65/75\n",
            "925/925 - 8s - loss: 0.2092 - binary_crossentropy: 0.6043 - val_loss: 0.2428 - val_binary_crossentropy: 0.6034\n",
            "Epoch 66/75\n",
            "925/925 - 8s - loss: 0.2097 - binary_crossentropy: 0.6049 - val_loss: 0.3651 - val_binary_crossentropy: 0.5007\n",
            "Epoch 67/75\n",
            "925/925 - 8s - loss: 0.2103 - binary_crossentropy: 0.6053 - val_loss: 0.3118 - val_binary_crossentropy: 0.7784\n",
            "Epoch 68/75\n",
            "925/925 - 8s - loss: 0.2107 - binary_crossentropy: 0.6074 - val_loss: 0.2361 - val_binary_crossentropy: 0.6499\n",
            "Epoch 69/75\n",
            "925/925 - 8s - loss: 0.2101 - binary_crossentropy: 0.6058 - val_loss: 0.2410 - val_binary_crossentropy: 0.6876\n",
            "Epoch 70/75\n",
            "925/925 - 8s - loss: 0.2102 - binary_crossentropy: 0.6068 - val_loss: 0.2366 - val_binary_crossentropy: 0.6678\n",
            "Epoch 71/75\n",
            "925/925 - 8s - loss: 0.2102 - binary_crossentropy: 0.6067 - val_loss: 0.3034 - val_binary_crossentropy: 0.8298\n",
            "Epoch 72/75\n",
            "925/925 - 8s - loss: 0.2097 - binary_crossentropy: 0.6069 - val_loss: 0.2390 - val_binary_crossentropy: 0.6049\n",
            "Epoch 73/75\n",
            "925/925 - 8s - loss: 0.2094 - binary_crossentropy: 0.6067 - val_loss: 0.2412 - val_binary_crossentropy: 0.6993\n",
            "Epoch 74/75\n",
            "925/925 - 8s - loss: 0.2101 - binary_crossentropy: 0.6070 - val_loss: 0.3238 - val_binary_crossentropy: 0.5045\n",
            "Epoch 75/75\n",
            "925/925 - 8s - loss: 0.2096 - binary_crossentropy: 0.6049 - val_loss: 0.2476 - val_binary_crossentropy: 0.6860\n",
            "/content/drive/MyDrive/eluvio/test_model3.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwlqp8rPrG7J"
      },
      "source": [
        "**The metrics are calcuated here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XboVlEH7caf_"
      },
      "source": [
        "directory = '/content/drive/MyDrive/data'\n",
        "files = os.listdir(directory) \n",
        "total_files = len(files) #Calculate total number of files "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHyEqi3vhZo_"
      },
      "source": [
        "l = 0\n",
        "window = 7 # Window needs to be an int greater than 1 and odd!\n",
        "first = int((window - 1)/2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjeqNZVehbuv"
      },
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/eluvio/test_model3.h5', compile = False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0QtwmnAhgCM"
      },
      "source": [
        "pr_dict = dict()\n",
        "for i in range(51,64):\n",
        "    \n",
        "    filename = directory + '/' + files[i]\n",
        "    f = open(filename, 'rb')\n",
        "    data = pickle.load(f)\n",
        "    f.close()\n",
        "        \n",
        "    feat1 = data['place']\n",
        "    feat1 = feat1.data.numpy() #convert tensors into numpy arrays for sklearn\n",
        "    feat1_size = feat1.shape[1]\n",
        "    \n",
        "    feat2 = data['cast']\n",
        "    feat2 = feat2.data.numpy()\n",
        "    feat2_size = feat2.shape[1]\n",
        "    \n",
        "    feat3 = data['action']\n",
        "    feat3 = feat3.data.numpy()\n",
        "    feat3_size = feat3.shape[1]\n",
        "    \n",
        "    feat4 = data['audio']\n",
        "    feat4 = feat4.data.numpy()\n",
        "    feat4_size = feat4.shape[1]\n",
        "    \n",
        "    x = np.hstack((feat1, feat2, feat3, feat4))\n",
        "    #y = data['scene_transition_boundary_ground_truth']\n",
        "    #y_new = y.data.numpy()\n",
        "            \n",
        "    scaler = preprocessing.MinMaxScaler().fit(x)\n",
        "    x_scaled = scaler.transform(x)\n",
        " \n",
        "    # Pad the start and end with zeros \n",
        "    padding = np.zeros((first, x_scaled.shape[1]))\n",
        "    x_scaled = np.concatenate((padding, x_scaled, padding), axis=0)\n",
        "                \n",
        "    #Fold the data set to obtain features from adjoining shots\n",
        "    N = x_scaled.shape[0] #changed from x_scaled\n",
        "    j = 0\n",
        "    #GT = []\n",
        "\n",
        "    for p in range(first, (N - first) - 1):\n",
        "        #window_range = np.arange(start = p - first, stop = p + first + 1)\n",
        "        temp1 = x_scaled[p - first: p + first + 1, :]\n",
        "        #print(p - first, p + first + 1, p - first, temp1.shape[0], temp1.shape[1])\n",
        "        temp1 = np.reshape(temp1, (1, window, temp1.shape[1]))\n",
        "        \n",
        "        #temp2 = y[p - first].data.numpy()\n",
        "        #print(p -first)\n",
        "        #temp2 = str(temp2)\n",
        "        if(j == 0):\n",
        "            X = temp1\n",
        "        else:\n",
        "            X = np.concatenate((X, temp1), axis=0)\n",
        "\n",
        "        #GT.append(temp2)\n",
        "        j = j + 1    \n",
        "\n",
        "    predictions=model.predict(X)\n",
        "    pr_dict[data[\"imdb_id\"]] = predictions\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22kAod6khiBs"
      },
      "source": [
        "gt_dict = dict()\n",
        "#pr_dict = dict()\n",
        "shot_to_end_frame_dict = dict()\n",
        "for i in range(51,64):\n",
        "    \n",
        "    filename = directory + '/' + files[i]\n",
        "    x = pickle.load(open(filename, \"rb\"))\n",
        "\n",
        "    gt_dict[x[\"imdb_id\"]] = x[\"scene_transition_boundary_ground_truth\"]\n",
        "    #pr_dict[x[\"imdb_id\"]] = x[\"scene_transition_boundary_prediction\"]\n",
        "    shot_to_end_frame_dict[x[\"imdb_id\"]] = x[\"shot_end_frame\"]\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKt0K5Ibm9vQ"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "def calc_ap(gt_dict, pr_dict):\n",
        "    \"\"\"Average Precision (AP) for scene transitions.\n",
        "    Args:\n",
        "        gt_dict: Scene transition ground-truths.\n",
        "        pr_dict: Scene transition predictions.\n",
        "    Returns:\n",
        "        AP, mean AP, and a dict of AP for each movie.\n",
        "    \"\"\"\n",
        "    assert gt_dict.keys() == pr_dict.keys()\n",
        "\n",
        "    AP_dict = dict()\n",
        "    gt = list()\n",
        "    pr = list()\n",
        "    for imdb_id in gt_dict.keys():\n",
        "        AP_dict[imdb_id] = average_precision_score(gt_dict[imdb_id], pr_dict[imdb_id])\n",
        "        gt.append(gt_dict[imdb_id])\n",
        "        pr.append(pr_dict[imdb_id])\n",
        "\n",
        "    mAP = sum(AP_dict.values()) / len(AP_dict)\n",
        "\n",
        "    gt = np.concatenate(gt)\n",
        "    pr = np.concatenate(pr)\n",
        "    AP = average_precision_score(gt, pr)\n",
        "\n",
        "    return AP, mAP, AP_dict\n",
        "\n",
        "\n",
        "def calc_miou(gt_dict, pr_dict, shot_to_end_frame_dict, threshold=0.5):\n",
        "    \"\"\"Maximum IoU (Miou) for scene segmentation.\n",
        "    Miou measures how well the predicted scenes and ground-truth scenes overlap. The descriptions can be found in\n",
        "    https://arxiv.org/pdf/1510.08893.pdf. Note the length of intersection or union is measured by the number of frames.\n",
        "    Args:\n",
        "        gt_dict: Scene transition ground-truths.\n",
        "        pr_dict: Scene transition predictions.\n",
        "        shot_to_end_frame_dict: End frame index for each shot.\n",
        "        threshold: A threshold to filter the predictions.\n",
        "    Returns:\n",
        "        Mean MIoU, and a dict of MIoU for each movie.\n",
        "    \"\"\"\n",
        "\n",
        "    def iou(x, y):\n",
        "        s0, e0 = x\n",
        "        s1, e1 = y\n",
        "        smin, smax = (s0, s1) if s1 > s0 else (s1, s0)\n",
        "        emin, emax = (e0, e1) if e1 > e0 else (e1, e0)\n",
        "        return (emin - smax + 1) / (emax - smin + 1)\n",
        "\n",
        "    def scene_frame_ranges(scene_transitions, shot_to_end_frame):\n",
        "        end_shots = np.where(scene_transitions)[0]\n",
        "        scenes = np.zeros((len(end_shots) + 1, 2), dtype=end_shots.dtype)\n",
        "        scenes[:-1, 1] = shot_to_end_frame[end_shots]\n",
        "        scenes[-1, 1] = shot_to_end_frame[len(scene_transitions)]\n",
        "        scenes[1:, 0] = scenes[:-1, 1] + 1\n",
        "        return scenes\n",
        "\n",
        "    def miou(gt_array, pr_array, shot_to_end_frame):\n",
        "        gt_scenes = scene_frame_ranges(gt_array, shot_to_end_frame)\n",
        "        pr_scenes = scene_frame_ranges(pr_array >= threshold, shot_to_end_frame)\n",
        "        assert gt_scenes[-1, -1] == pr_scenes[-1, -1]\n",
        "\n",
        "        m = gt_scenes.shape[0]\n",
        "        n = pr_scenes.shape[0]\n",
        "\n",
        "        # IoU for (gt_scene, pr_scene) pairs\n",
        "        iou_table = np.zeros((m, n))\n",
        "\n",
        "        j = 0\n",
        "        for i in range(m):\n",
        "            # j start prior to i end\n",
        "            while pr_scenes[j, 0] <= gt_scenes[i, 1]:\n",
        "                iou_table[i, j] = iou(gt_scenes[i], pr_scenes[j])\n",
        "                if j < n - 1:\n",
        "                    j += 1\n",
        "                else:\n",
        "                    break\n",
        "            # j end prior to (i + 1) start\n",
        "            if pr_scenes[j, 1] < gt_scenes[i, 1] + 1:\n",
        "                break\n",
        "            # j start later than (i + 1) start\n",
        "            if pr_scenes[j, 0] > gt_scenes[i, 1] + 1:\n",
        "                j -= 1\n",
        "        assert np.isnan(iou_table).sum() == 0\n",
        "        assert iou_table.min() >= 0\n",
        "\n",
        "        # Miou\n",
        "        return (iou_table.max(axis=0).mean() + iou_table.max(axis=1).mean()) / 2\n",
        "\n",
        "    assert gt_dict.keys() == pr_dict.keys()\n",
        "\n",
        "    miou_dict = dict()\n",
        "\n",
        "    for imdb_id in gt_dict.keys():\n",
        "        miou_dict[imdb_id] = miou(gt_dict[imdb_id], pr_dict[imdb_id], shot_to_end_frame_dict[imdb_id])\n",
        "    mean_miou = sum(miou_dict.values()) / len(miou_dict)\n",
        "\n",
        "    return mean_miou, miou_dict\n",
        "\n",
        "\n",
        "def calc_precision_recall(gt_dict, pr_dict, threshold=0.5):\n",
        "    \"\"\"Precision, Recall and F1 for scene transitions at a given threshold.\n",
        "    Args:\n",
        "        gt_dict: Scene transition ground-truths.\n",
        "        pr_dict: Scene transition predictions.\n",
        "        threshold: A threshold to filter the predictions.\n",
        "    Returns:\n",
        "        Mean Precision, Recall, and F1, per IMDB ID Precisions, Recalls, and F1 scores.\n",
        "    \"\"\"\n",
        "\n",
        "    def precision_recall(gt_array, pr_array):\n",
        "        tp_fn = gt_array == 1\n",
        "        tp_fp = pr_array >= threshold\n",
        "\n",
        "        tps = (tp_fn & tp_fp).sum()\n",
        "\n",
        "        precision = tps / tp_fp.sum()\n",
        "        recall = tps / tp_fn.sum()\n",
        "\n",
        "        return np.nan_to_num(precision), np.nan_to_num(recall)\n",
        "\n",
        "    assert gt_dict.keys() == pr_dict.keys()\n",
        "\n",
        "    precision_dict = dict()\n",
        "    recall_dict = dict()\n",
        "    fscore_dict = dict()\n",
        "\n",
        "    for imdb_id in gt_dict.keys():\n",
        "        p, r = precision_recall(gt_dict[imdb_id], pr_dict[imdb_id])\n",
        "        precision_dict[imdb_id] = p\n",
        "        recall_dict[imdb_id] = r\n",
        "        fscore_dict[imdb_id] = 2 * p * r / (p + r)\n",
        "\n",
        "    n = len(gt_dict)\n",
        "    mean_precision = sum(precision_dict.values()) / n\n",
        "    mean_recall = sum(recall_dict.values()) / n\n",
        "    mean_fscore = sum(fscore_dict.values()) / n\n",
        "\n",
        "    return mean_precision, mean_recall, mean_fscore, precision_dict, recall_dict, fscore_dict"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQqOtMatnFDf",
        "outputId": "7cf308a8-83cf-4840-ce6c-0d50eeb6c910"
      },
      "source": [
        "import json\n",
        "scores = dict()\n",
        "\n",
        "scores[\"AP\"], scores[\"mAP\"], _ = calc_ap(gt_dict, pr_dict)\n",
        "scores[\"Miou\"], _ = calc_miou(gt_dict, pr_dict, shot_to_end_frame_dict)\n",
        "scores[\"Precision\"], scores[\"Recall\"], scores[\"F1\"], *_ = calc_precision_recall(gt_dict, pr_dict)\n",
        "\n",
        "print(\"Scores:\", json.dumps(scores, indent=4))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores: {\n",
            "    \"AP\": 0.1435839777948291,\n",
            "    \"mAP\": 0.1519404850531079,\n",
            "    \"Miou\": 0.3321781278961218,\n",
            "    \"Precision\": 152.92307692307693,\n",
            "    \"Recall\": 694.4615384615385,\n",
            "    \"F1\": 246.37457483717378\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QiuapihnIQz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}